---
title: "SF Bay Microplastics Probability Distributions"
author: "Scott Coffin"
date: "1/13/2021"
output:   
  html_document:
    code_folding: hide
    theme: journal
    toc: yes
    toc_float: yes
    toc_depth: 6
    number_sections: true
    includes:
     # after_body: footer.html
  word_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',
                      warning=FALSE, message=FALSE,time_it = TRUE) #report
```

The objective of this project is to determine site-specific SSDs for plastic particles in the SF Bay. Particle distribution data for plastic particles is from the CEDEN databse, which was downloaded and sent to me by Dr. Diana Lin at SFEI ("2020-09-08_MooreParticleData.xlsx")

#library
```{r}
library(tidyverse)
library(ssdtools)
library(fitdistrplus)
library(rbin)
library(ggpmisc)
```
# Constants and Functions
```{r}
my.formula <- y ~ x # for linear plotting
```



# SF Bay Data
## Import data
```{r}
#site-specific distribution data
#SF bay data for all particles obtained via all sampling apparatus' for all matrices
distributions <- readxl::read_xlsx("data/2020-09-08_MooreParticleData.xlsx") %>%
  mutate(Size_um = 1000 * Length.mm) %>% 
#annotate matrices
    mutate(matrix = case_when(grepl("sediment", MatrixName) ~ "sediment",
                            grepl("runoff", MatrixName) ~ "runoff",
                            grepl("samplewater", MatrixName) ~ "samplewater",
                            grepl("tissue", MatrixName) ~ "tissue",
                            grepl("blankwater", MatrixName) ~ "blankwater",
                            grepl("effluent", MatrixName) ~ "effluent")) %>% 
  #annotate size cutoffs
  mutate(lower_size_limit_um = as.numeric(case_when(grepl(">125",MatrixName) ~ "125",
                                                 grepl(">355",MatrixName) ~ "355",
                                                 grepl(">500",MatrixName) ~ "500",
                                                 grepl(">1",MatrixName) ~ "1000"))) %>%
  #annotate size cutoffs
  mutate(upper_size_limit_um = as.numeric(case_when(grepl("125 um",MatrixName) ~ "125",
                                                 grepl("355 um",MatrixName) ~ "355",
                                                 grepl("500 um",MatrixName) ~ "500",
                                                 grepl("1000 um",MatrixName) ~ "1000"))) %>% 
  mutate_if(is.character,  as.factor)

skimr::skim(distributions)
```
```{r}
#This dataset contains a mixture of polymer types, including known plastics, known non-plastics, and unknowns. Summarize below
sum <- distributions %>% 
  group_by(PlasticType) %>% 
  summarize(count = n()) %>% 
  mutate(freq = formattable::percent(count/sum(count))) %>% 
  arrange(desc(freq))

sum
```
How many were unknown or natural?
```{r}
sum %>% 
  mutate(general = case_when(
    #reclassify with word extraction
    grepl("Unknown", PlasticType, ignore.case = TRUE) ~ "unknown",
    grepl("anthropogenic", PlasticType, ignore.case = TRUE) ~ "unknown",
    grepl("natural", PlasticType, ignore.case = TRUE) ~ "natural",
    #further manually reclassify
    PlasticType == "Wool" ~ "natural",
    PlasticType == "Cotton" ~ "natural",
    PlasticType == "Cellulosic" ~ "natural",
    PlasticType == "Glass" ~ "anthropogenic (not plastic)",
    PlasticType == "Asphalt" ~ "anthropogenic (not plastic)",
    PlasticType == "Not Characterized" ~ "Not Characterized"
    )) %>% 
  replace_na(list(general = "plastic")) %>% 
  group_by(general) %>% 
  summarize(freq_total = sum(freq)) %>% 
  janitor::adorn_totals()
```
###Remove non-plastic particles and other unidentified matter
To increase certainty in size distribution estimates, ONLY confirmed plastic particles will be used. 
```{r}
#list levels for plastic ID
levels(distributions$PlasticType)

distributions <- distributions %>% 
     mutate(general = case_when(
    grepl("Unknown", PlasticType, ignore.case = TRUE) ~ "unknown",
    grepl("anthropogenic", PlasticType, ignore.case = TRUE) ~ "anthropogenic (not plastic)",
    grepl("natural", PlasticType, ignore.case = TRUE) ~ "natural",
    PlasticType == "Non-Synthetic Fiber (cotton, silk, wool)" ~ "natural",
    PlasticType == "Wool" ~ "natural",
    PlasticType == "Cotton" ~ "natural",
    PlasticType == "Cellulosic" ~ "natural",
    PlasticType == "Glass" ~ "anthropogenic (not plastic)",
    PlasticType == "Asphalt" ~ "anthropogenic (not plastic)",
    PlasticType == "Not Characterized" ~ "Not Characterized",
    PlasticType == "Stearates, Lubricants" ~ "anthropogenic (not plastic)"
    )) %>% 
  replace_na(list(general = "plastic")) %>% 
  #remove non-plastics
  filter(general == "plastic") %>% 
    #filter(!str_detect(SampleID, "DUP")) %>% 
  filter(!str_detect(SampleID, "blank")) %>% #remove blanks
  #annotate season
  mutate(season = case_when(grepl("Nov|Dec|Jan|Feb|Mar", SampleID, ignore.case = TRUE) ~ "wet",
                            grepl("Aug|Sep", SampleID, ignore.case = TRUE) ~ "dry")) %>% 
   mutate(site = case_when(
    grepl("NB", SampleID,ignore.case = FALSE) ~ "North Bay",
    grepl("CB", SampleID,ignore.case = FALSE) ~ "Central Bay",
    grepl("SB10", SampleID,ignore.case = FALSE) ~ "South Bay",
    grepl("SB11", SampleID,ignore.case = FALSE) ~ "South Bay",
    grepl("SB12", SampleID,ignore.case = FALSE) ~ "South Bay",
    grepl("SB13", SampleID,ignore.case = FALSE) ~ "South Bay",
    grepl("LSB", SampleID,ignore.case = FALSE) ~ "Lower South Bay",
    grepl("NMS", SampleID,ignore.case = FALSE) ~ "National Marine Sanctuary",
    grepl("TB", SampleID,ignore.case = FALSE) ~ "Tomales Bay",
    grepl("SC", SampleID,ignore.case = FALSE) ~ "general",
    grepl("SUB", SampleID,ignore.case = FALSE) ~ "Suisin Bay",
    grepl("SOSL", SampleID,ignore.case = FALSE) ~ "general",
    grepl("Treasure", SampleID,ignore.case = FALSE) ~ "Central Bay",
    grepl("SPB", SampleID,ignore.case = FALSE) ~ "San Pablo Bay",
  ))

skimr::skim(distributions)
```
### Data export
```{r}
write.csv(distributions,
          "output/data/cleanParticleData.csv")
```


## Modelling
### Visualization
Visualize size distribution across all matrices
```{r}
distributions %>% 
  ggplot(aes(x = Size_um)) +
  geom_histogram() +
  scale_x_continuous(name = "Size (um)",breaks = scales::trans_breaks("log10", function(x) 10^x),labels = comma_signif, trans = "log10")+
  theme_minimal()
```
We can see here that they do not exactly follow an alpha distribution, but this is likely due to detection limits.

```{r}
distributions %>% 
  group_by(matrix) %>% 
  summarize(count = n()) %>% 
  mutate(fraction_total = count /  sum(count)) %>% 
  ggplot(aes(x = matrix, y = fraction_total, fill = matrix)) +
  geom_col() +
  labs(title = "Relative Fraction of particles by matrix") +
  theme_minimal()

```

Matrix Names:
"effluent" = wastewater treatment plant discharge
"runoff" = stormwater runoff
"samplewater" = surface water obtained using Manta Trawl or 1-L grab samples
"tissue" = fish tissue

### Determine maximum size for which the dataset
The maximum size for which the dataset was valid is determined using a theoretical particle
detection limit (PDL). 

1. Data was plotted using only the values between the minimum and the first non-detect.  A log-log plot for size vs abundance (#) is made.
2. A linear trendline was fitted, and the parameters for the function y = a*x + b were
obtained
3. Assuming y = 0 (equals 1 particle since 10^0 = 1), a value for x (the PDL) was calculated
4. Data were plotted using only the values between the minimum and the calculated PDL
5. If more data were included than in step 1, the procedure was repeated.
6. Once the PDL does not change anymore, only data between the minimum and PDL were
included for the final trendline fitting.


```{r}
sample_water <- distributions %>% 
  filter(matrix == "samplewater", #surface water
         lower_size_limit_um == 125) %>% 
  group_by(Size_um, lower_size_limit_um, upper_size_limit_um, SampleMatrix) %>% 
  summarize(abundance = n())

sample_water %>% 
  ggplot(aes(x = Size_um, y = abundance)) +
  geom_point() +
  geom_smooth(method = "lm", se=FALSE, formula = my.formula) +
   stat_poly_eq(formula = my.formula, 
                aes(label = paste(..eq.label.., ..rr.label.., ..p.value.label.., sep = "~~~")),
                label.x  = "right",
                label.y = "top",
                parse = TRUE) +         
  scale_x_log10() +
  scale_y_log10()
```
Here we can see that the particles do not cleanly fit an expected log-log trendline which is likely due to the way in which particle lengths are annotated. We could try rounding the particle lengths.

```{r}
distributions %>% 
  filter(matrix == "samplewater",
         lower_size_limit_um == 125) %>% 
  mutate(rounded_size_um = round(Size_um, -2)) %>% #round to the 100th place
  filter(rounded_size_um >= 125) %>% #if lower size limit is 125 um, ensure no particles below are considered
  filter(rounded_size_um > 400 & rounded_size_um <5000) %>%  #400 um seems to be where size counting tails off, and 5,000 um is arbitrary upper size limit for microplastics
  group_by(rounded_size_um , lower_size_limit_um, upper_size_limit_um, SampleMatrix) %>% 
  summarize(abundance = n()) %>% 
  ggplot(aes(x = rounded_size_um, y = abundance)) +
  geom_point() +
  geom_smooth(method = "lm", se=FALSE, formula = my.formula) +
   stat_poly_eq(formula = my.formula, 
                aes(label = paste(..eq.label.., ..rr.label.., ..p.value.label.., sep = "~~~")),
                label.x  = "right",
                label.y = "top",
                parse = TRUE) +    
  scale_x_log10() +
  scale_y_log10()
```


```{r}
distributions %>% 
  filter(matrix == "samplewater") %>%
  filter(MorphologicalCategory == "Fragment") %>% 
  ggplot(aes(x = Size_um)) +
  geom_histogram(alpha = 0.5) +
 # geom_smooth(method = "lm") +
  scale_x_log10() +
  scale_y_log10()
```

```{r}
distributions %>% 
  #filter(matrix == "samplewater") %>%
  #filter(MorphologicalCategory == "Fragment") %>% 
  ggplot(aes(x = Size_um, fill = matrix)) +
  geom_histogram(alpha = 0.5) +
 # geom_smooth(method = "lm") +
  scale_x_log10() +
  scale_y_log10()
```
```{r}

```


We need a better way of binning data.

Winsorized binning is similar to equal length binning except that both tails are cut off to obtain a smooth binning result. This technique is often used to remove outliers during the data pre-processing stage. For Winsorized binning, the Winsorized statistics are computed first. After the minimum and maximum have been found, the split points are calculated the same way as in equal length binning.


#### SampleWater
```{r}
#determine lower and upper end based on maximum R^2 (iteration required)
sample_water_cut <- distributions %>% 
  #filter(lower_size_limit_um == 125) %>% 
 # filter(MorphologicalCategory == "Fragment") %>% 
  filter(matrix == "samplewater") %>% 
  #filter(Size_um >1 & Size_um  <1000) %>% 
  drop_na(Size_um)

#cut into bins
#sample_waterwinsors <- rbin_winsorize(sample_water_cut, polymer, Size_um, 20)
sample_waterwinsors <- rbin_winsorize(sample_water_cut, predictor = Size_um, Size_um, bins = 25, winsor_rate = 0.05, remove_na = TRUE)
#save as dataframe
sample_waterbinned <- as.data.frame(sample_waterwinsors$bins) %>% 
  dplyr::select(c(cut_point, bin_count, bin_prop))

#strip of characters
sample_waterbinned$cut <- gsub("[^0-9.-]","",sample_waterbinned$cut_point)
 #convert to numeric
sample_waterbinned2 <- sample_waterbinned %>% 
  mutate(cut.numeric = as.numeric(cut)) %>% 
  mutate(logAbundance = log10(bin_prop),
         logSize = log10(cut.numeric))


p <- sample_waterbinned2 %>% 
  #filter(logAbundance < -1.0) %>% 
  ggplot(aes(x = logSize, y = logAbundance)) +
   geom_smooth(method = "lm", se=FALSE, color="black", formula = my.formula) +
   stat_poly_eq(formula = my.formula, 
                aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
                parse = TRUE) +         
   geom_point() +
  xlab("Log (Size, um)") +
  ylab("Log (Relative abundance, %)")
p
```


##### Remove outliers
```{r}
sample_waterlin <- lm(logAbundance ~ logSize, data = sample_waterbinned2)
cooksd <- cooks.distance(sample_waterlin)
plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance
abline(h = 4*mean(cooksd, na.rm=T), col="red")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4*mean(cooksd, na.rm=T),names(cooksd),""), col="red")  # add labels
```
Extract outliers
```{r}
influential <- as.numeric(names(cooksd)[(cooksd > 4*mean(cooksd, na.rm=T))])  # influential row numbers
head(sample_waterbinned2[influential, ])  # influential observations.
```
```{r}
trimmedsample_water <- sample_waterbinned2[-influential,] %>% 
  mutate(polymer = "sample_water")

sample_waterlin <- lm(logAbundance ~ logSize, data = trimmedsample_water)
sample_waterlin.summ <- summary(sample_waterlin)
sample_waterlin.summ
```
```{r}
ggplot(data = trimmedsample_water, aes(x = logSize, y = logAbundance)) +
   geom_smooth(method = "lm", se=FALSE, color="black", formula = my.formula) +
   stat_poly_eq(formula = my.formula, 
                aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
                parse = TRUE) +         
   geom_point() +
  xlab("Log (Size, um)") +
  ylab("Log (Relative abundance, %)")
```
##### Manta only
```{r}
#determine lower and upper end based on maximum R^2 (iteration required)
sample_water_cut <- distributions %>% 
  filter(lower_size_limit_um == 125) %>% 
 # filter(MorphologicalCategory == "Fragment") %>% 
  filter(matrix == "samplewater") %>% 
  #filter(Size_um >1 & Size_um  <1000) %>% 
  drop_na(Size_um)

#cut into bins
#sample_waterwinsors <- rbin_winsorize(sample_water_cut, polymer, Size_um, 20)
sample_waterwinsors <- rbin_winsorize(sample_water_cut, predictor = Size_um, Size_um, bins = 23, winsor_rate = 0.05, remove_na = TRUE)
#save as dataframe
sample_waterbinned <- as.data.frame(sample_waterwinsors$bins) %>% 
  dplyr::select(c(cut_point, bin_count, bin_prop))

#strip of characters
sample_waterbinned$cut <- gsub("[^0-9.-]","",sample_waterbinned$cut_point)
 #convert to numeric
sample_waterbinned2 <- sample_waterbinned %>% 
  mutate(cut.numeric = as.numeric(cut)) %>% 
  mutate(logAbundance = log10(bin_prop),
         logSize = log10(cut.numeric))

## model
library(ggpmisc)
my.formula <- y ~ x
p <- sample_waterbinned2 %>% 
  #filter(logAbundance < -1.0) %>% 
  ggplot(aes(x = logSize, y = logAbundance)) +
   geom_smooth(method = "lm", se=FALSE, color="black", formula = my.formula) +
   stat_poly_eq(formula = my.formula, 
                aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
                parse = TRUE) +         
   geom_point() +
  xlab("Log (Size, um)") +
  ylab("Log (Relative abundance, %)")
p
```


###### Remove outliers
```{r}
sample_waterlin <- lm(logAbundance ~ logSize, data = sample_waterbinned2)
cooksd <- cooks.distance(sample_waterlin)
plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance
abline(h = 4*mean(cooksd, na.rm=T), col="red")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4*mean(cooksd, na.rm=T),names(cooksd),""), col="red")  # add labels
```
Extract outliers
```{r}
influential <- as.numeric(names(cooksd)[(cooksd > 4*mean(cooksd, na.rm=T))])  # influential row numbers
head(sample_waterbinned2[influential, ])  # influential observations.
```
```{r}
trimmedsample_water <- sample_waterbinned2[-influential,] %>% 
  mutate(polymer = "sample_water")

sample_waterlin <- lm(logAbundance ~ logSize, data = trimmedsample_water)
sample_waterlin.summ <- summary(sample_waterlin)
sample_waterlin.summ
```
```{r}
ggplot(data = trimmedsample_water, aes(x = logSize, y = logAbundance)) +
   geom_smooth(method = "lm", se=FALSE, color="black", formula = my.formula) +
   stat_poly_eq(formula = my.formula, 
                aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
                parse = TRUE) +         
   geom_point() +
  xlab("Log (Size, um)") +
  ylab("Log (Relative abundance, %)")
```

### Effluent
```{r}
#determine lower and upper end based on maximum R^2 (iteration required)
effluent_cut <- distributions %>% 
  #filter(lower_size_limit_um == 125) %>% 
 # filter(MorphologicalCategory == "Fragment") %>% 
  filter(matrix == "effluent") %>% 
  #filter(Size_um >1 & Size_um  <1000) %>% 
  drop_na(Size_um)

#cut into bins
#effluentwinsors <- rbin_winsorize(effluent_cut, polymer, Size_um, 20)
effluentwinsors <- rbin_winsorize(effluent_cut, predictor = Size_um, Size_um, bins = 25, winsor_rate = 0.05)
#save as dataframe
effluentbinned <- as.data.frame(effluentwinsors$bins) %>% 
  dplyr::select(c(cut_point, bin_count, bin_prop))

#strip of characters
effluentbinned$cut <- gsub("[^0-9.-]","",effluentbinned$cut_point)
 #convert to numeric
effluentbinned2 <- effluentbinned %>% 
  mutate(cut.numeric = as.numeric(cut)) %>% 
  mutate(logAbundance = log10(bin_prop),
         logSize = log10(cut.numeric))

## model
library(ggpmisc)
my.formula <- y ~ x
p <- effluentbinned2 %>% 
  #filter(logAbundance < -1.0) %>% 
  ggplot(aes(x = logSize, y = logAbundance)) +
   geom_smooth(method = "lm", se=FALSE, color="black", formula = my.formula) +
   stat_poly_eq(formula = my.formula, 
                aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
                parse = TRUE) +         
   geom_point() +
  xlab("Log (Size, um)") +
  ylab("Log (Relative abundance, %)")
p
```


##### Remove outliers
```{r}
effluentlin <- lm(logAbundance ~ logSize, data = effluentbinned2)
cooksd <- cooks.distance(effluentlin)
plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance
abline(h = 4*mean(cooksd, na.rm=T), col="red")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4*mean(cooksd, na.rm=T),names(cooksd),""), col="red")  # add labels
```
Extract outliers
```{r}
influential <- as.numeric(names(cooksd)[(cooksd > 4*mean(cooksd, na.rm=T))])  # influential row numbers
head(effluentbinned2[influential, ])  # influential observations.
```
```{r}
trimmedeffluent <- effluentbinned2[-influential,] %>% 
  mutate(polymer = "effluent")

effluentlin <- lm(logAbundance ~ logSize, data = trimmedeffluent)
effluentlin.summ <- summary(effluentlin)
effluentlin.summ
```
```{r}
ggplot(data = trimmedeffluent, aes(x = logSize, y = logAbundance)) +
   geom_smooth(method = "lm", se=FALSE, color="black", formula = my.formula) +
   stat_poly_eq(formula = my.formula, 
                aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
                parse = TRUE) +         
   geom_point() +
  xlab("Log (Size, um)") +
  ylab("Log (Relative abundance, %)")
```
### runoff
```{r}
#determine lower and upper end based on maximum R^2 (iteration required)
runoff_cut <- distributions %>% 
  #filter(lower_size_limit_um == 125) %>% 
 # filter(MorphologicalCategory == "Fragment") %>% 
  filter(matrix == "runoff") %>% 
  #filter(Size_um >1 & Size_um  <1000) %>% 
  drop_na(Size_um)

#cut into bins
#runoffwinsors <- rbin_winsorize(runoff_cut, polymer, Size_um, 20)
runoffwinsors <- rbin_winsorize(runoff_cut, predictor = Size_um, Size_um, bins = 25, winsor_rate = 0.05)
#save as dataframe
runoffbinned <- as.data.frame(runoffwinsors$bins) %>% 
  dplyr::select(c(cut_point, bin_count, bin_prop))

#strip of characters
runoffbinned$cut <- gsub("[^0-9.-]","",runoffbinned$cut_point)
 #convert to numeric
runoffbinned2 <- runoffbinned %>% 
  mutate(cut.numeric = as.numeric(cut)) %>% 
  mutate(logAbundance = log10(bin_prop),
         logSize = log10(cut.numeric))

## model
library(ggpmisc)
my.formula <- y ~ x
p <- runoffbinned2 %>% 
  #filter(logAbundance < -1.0) %>% 
  ggplot(aes(x = logSize, y = logAbundance)) +
   geom_smooth(method = "lm", se=FALSE, color="black", formula = my.formula) +
   stat_poly_eq(formula = my.formula, 
                aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
                parse = TRUE) +         
   geom_point() +
  xlab("Log (Size, um)") +
  ylab("Log (Relative abundance, %)")
p
```


##### Remove outliers
```{r}
runofflin <- lm(logAbundance ~ logSize, data = runoffbinned2)
cooksd <- cooks.distance(runofflin)
plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance
abline(h = 4*mean(cooksd, na.rm=T), col="red")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4*mean(cooksd, na.rm=T),names(cooksd),""), col="red")  # add labels
```
Extract outliers
```{r}
influential <- as.numeric(names(cooksd)[(cooksd > 4*mean(cooksd, na.rm=T))])  # influential row numbers
head(runoffbinned2[influential, ])  # influential observations.
```
```{r}
trimmedrunoff <- runoffbinned2[-influential,] %>% 
  mutate(polymer = "runoff")

runofflin <- lm(logAbundance ~ logSize, data = trimmedrunoff)
runofflin.summ <- summary(runofflin)
runofflin.summ
```
```{r}
ggplot(data = trimmedrunoff, aes(x = logSize, y = logAbundance)) +
   geom_smooth(method = "lm", se=FALSE, color="black", formula = my.formula) +
   stat_poly_eq(formula = my.formula, 
                aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
                parse = TRUE) +         
   geom_point() +
  xlab("Log (Size, um)") +
  ylab("Log (Relative abundance, %)")
```

### Sediment
```{r}
#determine lower and upper end based on maximum R^2 (iteration required)
sediment_cut <- distributions %>% 
  #filter(lower_size_limit_um == 125) %>% 
 # filter(MorphologicalCategory == "Fragment") %>% 
  filter(matrix == "sediment") %>% 
  #filter(Size_um >1 & Size_um  <1000) %>% 
  drop_na(Size_um)

#cut into bins
#sedimentwinsors <- rbin_winsorize(sediment_cut, polymer, Size_um, 20)
sedimentwinsors <- rbin_winsorize(sediment_cut, predictor = Size_um, Size_um, bins = 19, winsor_rate = 0.05)
#save as dataframe
sedimentbinned <- as.data.frame(sedimentwinsors$bins) %>% 
  dplyr::select(c(cut_point, bin_count, bin_prop))

#strip of characters
sedimentbinned$cut <- gsub("[^0-9.-]","",sedimentbinned$cut_point)
 #convert to numeric
sedimentbinned2 <- sedimentbinned %>% 
  mutate(cut.numeric = as.numeric(cut)) %>% 
  mutate(logAbundance = log10(bin_prop),
         logSize = log10(cut.numeric))

## model
library(ggpmisc)
my.formula <- y ~ x
p <- sedimentbinned2 %>% 
  #filter(logAbundance < -1.0) %>% 
  ggplot(aes(x = logSize, y = logAbundance)) +
   geom_smooth(method = "lm", se=FALSE, color="black", formula = my.formula) +
   stat_poly_eq(formula = my.formula, 
                aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
                parse = TRUE) +         
   geom_point() +
  xlab("Log (Size, um)") +
  ylab("Log (Relative abundance, %)")
p
```


##### Remove outliers
```{r}
sedimentlin <- lm(logAbundance ~ logSize, data = sedimentbinned2)
cooksd <- cooks.distance(sedimentlin)
plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance
abline(h = 4*mean(cooksd, na.rm=T), col="red")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4*mean(cooksd, na.rm=T),names(cooksd),""), col="red")  # add labels
```
Extract outliers
```{r}
influential <- as.numeric(names(cooksd)[(cooksd > 4*mean(cooksd, na.rm=T))])  # influential row numbers
head(sedimentbinned2[influential, ])  # influential observations.
```
```{r}
trimmedsediment <- sedimentbinned2[-influential,] %>%
  mutate(polymer = "sediment")

sedimentlin <- lm(logAbundance ~ logSize, data = trimmedsediment)
sedimentlin.summ <- summary(sedimentlin)
sedimentlin.summ
```
```{r}
ggplot(data = trimmedsediment, aes(x = logSize, y = logAbundance)) +
   geom_smooth(method = "lm", se=FALSE, color="black", formula = my.formula) +
   stat_poly_eq(formula = my.formula, 
                aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
                parse = TRUE) +         
   geom_point() +
  xlab("Log (Size, um)") +
  ylab("Log (Relative abundance, %)")
```


### Tissue
```{r}
#determine lower and upper end based on maximum R^2 (iteration required)
tissue_cut <- distributions %>% 
  #filter(lower_size_limit_um == 125) %>% 
 # filter(MorphologicalCategory == "Fragment") %>% 
  filter(matrix == "tissue") %>% 
  #filter(Size_um >1 & Size_um  <1000) %>% 
  drop_na(Size_um)

#cut into bins
#tissuewinsors <- rbin_winsorize(tissue_cut, polymer, Size_um, 20)
tissuewinsors <- rbin_winsorize(tissue_cut, predictor = Size_um, Size_um, bins = 14, winsor_rate = 0.05)
#save as dataframe
tissuebinned <- as.data.frame(tissuewinsors$bins) %>% 
  dplyr::select(c(cut_point, bin_count, bin_prop))

#strip of characters
tissuebinned$cut <- gsub("[^0-9.-]","",tissuebinned$cut_point)
 #convert to numeric
tissuebinned2 <- tissuebinned %>% 
  mutate(cut.numeric = as.numeric(cut)) %>% 
  mutate(logAbundance = log10(bin_prop),
         logSize = log10(cut.numeric))

## model
library(ggpmisc)
my.formula <- y ~ x
p <- tissuebinned2 %>% 
  #filter(logAbundance < -1.0) %>% 
  ggplot(aes(x = logSize, y = logAbundance)) +
   geom_smooth(method = "lm", se=FALSE, color="black", formula = my.formula) +
   stat_poly_eq(formula = my.formula, 
                aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
                parse = TRUE) +         
   geom_point() +
  xlab("Log (Size, um)") +
  ylab("Log (Relative abundance, %)")
p
```


##### Remove outliers
```{r}
tissuelin <- lm(logAbundance ~ logSize, data = tissuebinned2)
cooksd <- cooks.distance(tissuelin)
plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance
abline(h = 4*mean(cooksd, na.rm=T), col="red")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4*mean(cooksd, na.rm=T),names(cooksd),""), col="red")  # add labels
```
Extract outliers
```{r}
influential <- as.numeric(names(cooksd)[(cooksd > 4*mean(cooksd, na.rm=T))])  # influential row numbers
head(tissuebinned2[influential, ])  # influential observations.
```
```{r}
trimmedtissue <- tissuebinned2[-influential,] %>%
  mutate(polymer = "tissue")

tissuelin <- lm(logAbundance ~ logSize, data = trimmedtissue)
tissuelin.summ <- summary(tissuelin)
tissuelin.summ
```
```{r}
ggplot(data = trimmedtissue, aes(x = logSize, y = logAbundance)) +
   geom_smooth(method = "lm", se=FALSE, color="black", formula = my.formula) +
   stat_poly_eq(formula = my.formula, 
                aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
                parse = TRUE) +         
   geom_point() +
  xlab("Log (Size, um)") +
  ylab("Log (Relative abundance, %)")
```

## Compare individual and all combined
### Scatterplot
```{r}
#recombine datasets
trimmed_combined <- rbind(trimmedeffluent %>% mutate(matrix = "effluent"), 
      trimmedrunoff %>% mutate(matrix = "runoff"),
      trimmedsample_water %>% mutate(matrix = "sample_water"),
      trimmedsediment %>% mutate(matrix = "sediment"),
      trimmedtissue %>% mutate(matrix = "tissue"))


scatterplot <- trimmed_combined %>% 
  ggplot(aes(x = 10^logSize, y = 10^logAbundance * 100, color = matrix, fill = matrix)) +
   geom_smooth(method = "lm", se=FALSE, formula = my.formula) +
   stat_poly_eq(formula = my.formula, 
                aes(label = paste(..eq.label.., ..rr.label.., ..p.value.label.., sep = "~~~")),
                label.x  = "right",
                label.y = "top",
                parse = TRUE) +         
  scale_color_discrete(labels = c("WWTP Effluent", "Stormwater Runoff", "Surface water", "Sediment", "Fish Tissue")) +
  scale_fill_discrete(labels = c("WWTP Effluent", "Stormwater Runoff", "Surface water", "Sediment", "Fish Tissue")) +
   geom_point() +
  scale_x_log10() + 
  scale_y_log10() +
  xlab("Size (Î¼m)") +
  ylab("Relative abundance (%)") +
  theme_bw(base_size = 18) +
  theme(legend.position = c(0.6,0.87),
        legend.title = element_blank(),
        #legend.background = element_rect(color = "black", fill = "white", linetype = "solid"),
        legend.text = element_text(size = 12))

scatterplot
```

```{r}
ggsave(plot = scatterplot,
       filename = "PDF_scatterplot.jpg",
       path = "./output/figures/",
       width = 12, height = 8, units = "in",
       dpi = 300)
```

### Table
```{r}
matrix <- c("samplewater", "effluent", "runoff", "sediment", "tissue")

count <- distributions %>% 
  filter(matrix != "blankwater") %>% 
  group_by(matrix) %>% 
  summarise(count = n())


Lmin <- c(min(trimmedsample_water$logSize), min(trimmedeffluent$logSize), min(trimmedrunoff$logSize), min(trimmedsediment$logSize), min(trimmedtissue$logSize))

preds <- c(sample_waterlin$coefficients[2], effluentlin$coefficients[2], runofflin$coefficients[2], sedimentlin$coefficients[2], tissuelin$coefficients[2])

stderrors <- c(sample_waterlin.summ$coefficients[2,2], effluentlin.summ$coefficients[2,2], runofflin.summ$coefficients[2,2], sedimentlin.summ$coefficients[2,2], tissuelin.summ$coefficients[2,2])

R2 <- c(sample_waterlin.summ$r.squared, effluentlin.summ$r.squared, runofflin.summ$r.squared, sedimentlin.summ$r.squared, tissuelin.summ$r.squared)

p.values <- c(sample_waterlin.summ$coefficients[2,4], effluentlin.summ$coefficients[2,4], runofflin.summ$coefficients[2,4], sedimentlin.summ$coefficients[2,4], tissuelin.summ$coefficients[2,4])

summary <- tibble(matrix,preds, stderrors, R2, p.values, Lmin) %>% 
  mutate(Lmin_um = 10^Lmin) %>% 
  dplyr::select(-Lmin) %>% 
  left_join(count)

summary

write.csv(summary,"output/data/PDFs.csv")
```



### Barplot
```{r eval=FALSE, include=FALSE}
summary %>% 
  ggplot(aes(x = names, y = preds, fill = R2)) +
  geom_col() +
  geom_errorbar(aes(xmin = stderrors, xmax = stderrors)) +
  ylim(c(0, -2))
  
```


### Fit distributions
The following section is incomplete.

```{r eval=FALSE, include=FALSE}
#beta test with one polymer
PS <- distributions %>% 
  filter(PlasticType == "Polystyrene")

descdist(PS$Size_um, boot = 1000)
```
```{r eval=FALSE, include=FALSE}
#fit log-normal distribution
lnorm <- fitdist(PS$Size_um, "lnorm")
summary(lnorm)
#fit gamma distribution
gamma <- fitdist(PS$Size_um, "gamma")
summary(gamma)

par(mfrow = c(2,2))
plot.legend <- c("lognormal", "gamma")
denscomp(list(lnorm, gamma), legendtext = plot.legend)
qqcomp(list(lnorm, gamma), legendtext = plot.legend)
cdfcomp(list(lnorm, gamma), legendtext = plot.legend)
ppcomp(list(lnorm, gamma), legendtext = plot.legend)
```
Which distributions fits the data best?
```{r eval=FALSE, include=FALSE}
gofstat(list(lnorm, gamma), fitnames = plot.legend)
```
