---
title: "SF Bay Microplastics Risk Characterization"
author: "Scott Coffin"
date: "12/15/2021"
output:   
  html_document:
    code_folding: hide
    theme: journal
    toc: yes
    toc_float: yes
    toc_depth: 6
    number_sections: true
    includes:
     # after_body: footer.html
  word_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',
                      warning=FALSE, message=FALSE,time_it = TRUE) #report
```

```{r}
library(tidyverse)
library(calecopal)
library(ssdtools)
library(DT)
library(plotly)
library(gridExtra)
library(grid)
library(wesanderson)
library(ggdark)
library(broom)
library(knitr)
library(ggdark)
library(viridis)
library(ggpubr)
library(ggsci)
library(stringr)
library(skimr)
library(ggpmisc)
```

# Hazard Concentration and Alignment Parameters
```{r}
###### Choose concentration alignment parameters####
alpha.stormwater <- 1.87
alpha.stormwater.sd <- 0.13
alpha.marine = 2.00 #based on SFEI dataset
alpha.marine.sd <- 0.15 #based on SFEI dataset
alpha.wastewater <- 1.58
alpha.wastewater.sd <- 0.11
alpha.sediment <- 2.10
alpha.sediment.sd <- 0.12
alpha.wastewater.sd <- 0.11
alpha.fish <- 1.75
alpha.fish.sd <- 0.17

#based on Kooi
alpha.freshwater = 2.64 #table s4 from Kooi et al 2021 for freshwater surface water. length


x2D_set = 5000 #100 #upper size range (microns)
x1D_set = 1 #1 #lower size range (microns)

#### Choose assessment factor (default = 1) ####
AF = 1

##### Choose hazard concentration and confidence intervals####
#particles/L
Threshold1 = 0.34 / AF
Threshold2 = 5.2 / AF
Threshold3 = 21.8 / AF
Threshold4 = 89.9 / AF

##### Food dilution thresholds (particles/L aligned to 1-5,000 um) ####
Threshold1_food = 0.34 / AF
Threshold2_food = 3.0 / AF
Threshold3_food = 5.0 / AF
Threshold4_food = 34 / AF
## 95% CI's ##
Threshold2_food_lcl = 0.3 / AF
Threshold2_food_hcl = 66 / AF
Threshold3_food_lcl = 0.4 / AF
Threshold3_food_hcl = 220 / AF
Threshold4_food_lcl = 2.5 / AF
Threshold4_food_hcl = 860 / AF


#Oxidative stress thresholds (particles/L aligned to 1-5,000 um)
Threshold1_oxidative.stress = 60 / AF
Threshold2_oxidative.stress = 320 / AF
Threshold3_oxidative.stress = 890 / AF
Threshold4_oxidative.stress = 4100 / AF
```

```{r Theme, include=FALSE}
#Theme type
     theme.type <- theme_bw(base_size = 15) +
                    theme(plot.title = element_text(hjust = 0.5),
                    plot.subtitle = element_text(hjust = 0.5))
     #color selection
     fill.type <-    scale_fill_viridis(discrete = TRUE)
     #color selection
     color.type <- scale_color_viridis(discrete = TRUE)
```



```{r}
# print table
kable(data.frame(
  Category = c("Hazard Concentrations (particles/L)"),
  "Threshold1" = Threshold1,
  "Threshold 2" = Threshold2,
  "Threshold 3" = Threshold3,
  "Threshold 4" = Threshold4))
```

```{r}
#print table of sizes
kable(data.frame(
  Category = c("Concentration Alignment Parameters"),
  "Marine Alpha" = alpha.marine,
  "Freshwater Alpha" = alpha.freshwater,
  "lower_size_range_microns" = x1D_set,
  "upper_size_range_microns" = x2D_set))
```
# Data Preparation

To compare thresholds to concentrations observed in the environment, data from the following study is used:

Zhu, Xia, Keenan Munno, Jelena Grbic, Larissa Meghan Werbowski, Jacqueline Bikker, Annissa Ho, Edie Guo, et al. 2021. “Holistic Assessment of Microplastics and Other Anthropogenic Microdebris in an Urban Bay Sheds Light on Their Sources and Fate.” ACS ES&T Water, May, acsestwater.0c00292. https://doi.org/10.1021/acsestwater.0c00292.

## Import
```{r}
#data import
#SF bay data from Zhu et al (2021)
sfBay <- read.csv("data/SFBayData.csv", na.strings = "NA", stringsAsFactors = TRUE) %>%
  rename(sampleID = ï..sampleID,
          x1M = Min.particle.size.um,
         x2M = Max.particle.size.um) %>% 
  mutate(Sample.Type = "sample") 
```

## Cleanup

### Wet/Dry Annotation
<!-- Data reported in Zhu et al (2021) are not annotated with wet/dry, however data from Sutton et al (2019) are. We could match these based on sampleID... -->
<!-- ```{r} -->
<!-- sfnotBlankCorrected <- read.csv("data/SFEI_notBlankCorrected.csv", na.strings = "NA", stringsAsFactors = TRUE) %>% -->
<!--   rename(sampleID = Sample.ID) -->
<!-- ``` -->

...or we could annotate samples taken between November and March as wet and August-September as dry based on the reporting in this spreadsheet. The grab samples are also paired with the manta samples by ID, so we need to split and recombine lengthwise.

<!-- ### Manta/Grab split % recombine -->
<!-- ```{r} -->
<!-- sfBay <- sfBay %>% -->
<!--  mutate(season = case_when(grepl("Nov|Dec|Jan|Feb|Mar", sampleID, ignore.case = TRUE) ~ "wet", -->
<!--                             grepl("Aug|Sep", sampleID, ignore.case = TRUE) ~ "dry")) -->

<!-- #split manta from grabs -->
<!-- sfBayManta <- sfBay %>% -->
<!--   #take out manta only -->
<!--   filter(Sampling.apparatus == "Manta Trawl") %>% -->
<!--   #extract string before space -->
<!--   mutate(sampleIDSimple = sub(" .*", "", sampleID)) -->

<!-- #extract grab sample only -->
<!-- sfBayGrab <- sfBay %>% -->
<!--   filter(Sampling.apparatus == "1-L grab") %>% -->
<!--   #remove extraneous info -->
<!--   mutate(sampleIDSimple = sampleID, -->
<!--          particle.L.master_grab = particle.L.master, -->
<!--          unaligned.particle.L.master_grab = unaligned.particle.L.master, -->
<!--          CF_grab = CF) %>% -->
<!--   dplyr::select(c(sampleIDSimple, particle.L.master_grab, unaligned.particle.L.master_grab, CF_grab)) -->

<!-- #recombine manta and grab lengthwise -->
<!-- sfBay_new <- left_join(sfBayManta, sfBayGrab, by = "sampleIDSimple") -->
<!-- ``` -->

Sample #CB9-Manta-11 Jan 18 should be omitted due to non-representative nature (in tidal front) (looks like it's already been removed?)
	


#### TRUE DATE MATCH
The following code only matches manta and grab that were collectyed on the same days.
```{r}
#grab_with_dates <- read.csv("data/grab_with_dates.csv") %>% 
# rename(sampleID_closestDate = ï..sampleID_closestDate) %>% 

grab_with_dates <-  readxl::read_excel("data/grab_with_dates.xlsx") %>% 
  rename(x1M = Min.particle.size.um,
         x2M = Max.particle.size.um) %>% 
  mutate(Sample.Type = "sample")

# first replace the dash with space
grab_with_dates$newDates <- str_replace(grab_with_dates$Date_string,"-", " ")

#then concat the station code with date to get the sampleID
dates <- grab_with_dates %>% 
  mutate(sampleID = paste(Station.Code, newDates)) %>% 
  rename(grab_particles.L.blank.corrected = particles.L.blank.corrected) %>% 
  rename(x1M_grab = x1M,
         x2M_grab = x2M)

#join with other dataset
true_matches <- full_join(sfBay %>%  
                   filter(Sampling.apparatus == "Manta Trawl") %>% 
                   rename(manta_particles.L.blank.corrected = particles.L.blank.corrected,
                          x1M_manta = x1M,
                          x2M_manta = x2M,
                          latitude_manta = latitude,
                          longitude_manta = longitude),
                 dates,
                 by = "sampleID") %>% 
  dplyr::select(c(sampleID, latitude_grab, longitude_grab, latitude_manta, longitude_manta, Station.Code, manta_particles.L.blank.corrected, grab_particles.L.blank.corrected, x1M_grab, x2M_grab, x1M_manta, x2M_manta, match)) %>% 
  #annotate wet/dry
  mutate(season = case_when(grepl("Nov|Dec|Jan|Feb|Mar", sampleID, ignore.case = TRUE) ~ "wet",
                            grepl("Aug|Sep", sampleID, ignore.case = TRUE) ~ "dry"))

#investiage matches
true_matches %>% skim()
```
##### Match
```{r}
#view matched data
my.formula <- y ~ x

match_plot_true_season <- true_matches %>% 
  drop_na(grab_particles.L.blank.corrected) %>% 
  filter(grab_particles.L.blank.corrected > 0) %>% #remove 0's that shouldn't belong
  ggplot(aes(x = manta_particles.L.blank.corrected, y = grab_particles.L.blank.corrected, color = season))+
  geom_point()+
  geom_smooth(method = "lm", se=FALSE, formula = my.formula) +
   stat_poly_eq(formula = my.formula, 
                aes(label = paste(..eq.label.., ..rr.label.., ..p.value.label.., sep = "~~~")), 
                parse = TRUE) +         
  scale_x_log10(name = "Manta Trawl blank-corrected particles/L",
                breaks = scales::trans_breaks("log10", function(x) 10^x),
        labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  scale_y_log10(name = "1L-grab blank-corrected particles/L") +
  theme.type +
   theme(legend.position = c(0.75,0.92),
        legend.title = element_blank(),
        legend.background = element_blank(),
        legend.text = element_text(size = 12))


match_plot_true_overall <- true_matches %>% 
  drop_na(grab_particles.L.blank.corrected) %>% 
  filter(grab_particles.L.blank.corrected > 0) %>% #remove 0's that shouldn't belong
  ggplot(aes(x = manta_particles.L.blank.corrected, y = grab_particles.L.blank.corrected))+
  geom_point()+
  geom_smooth(method = "lm", se=FALSE, formula = my.formula) +
   stat_poly_eq(formula = my.formula, 
                aes(label = paste(..eq.label.., ..rr.label.., ..p.value.label.., sep = "~~~")), 
                parse = TRUE) +         
  scale_x_log10(name = "Manta Trawl blank-corrected particles/L",
                breaks = scales::trans_breaks("log10", function(x) 10^x),
        labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  scale_y_log10(name = "1L-grab blank-corrected particles/L") +
  theme.type

ggarrange(match_plot_true_season, match_plot_true_overall)

```


#### CLOSEST DATE MATCH
The following code uses the nearest date to match manta and grab. In many cases, matches are one to several days apart.


##### Matched Manta and Grab
```{r}
#remove grab samples that don't have dates
sfBay_noGrab <- sfBay %>% 
  filter(Sampling.apparatus != "1-L grab")

grab_with_dates_closest <- grab_with_dates %>% 
  dplyr::select(-c(Station.Code, newDates, particle_count, sample_volume_L, Date_string, match, needs_fixing)) %>% 
  rename("latitude" = "latitude_grab",
         "longitude" = "longitude_grab")

#see matches
closestMatches <- full_join(sfBay_noGrab, grab_with_dates_closest %>%
                       rename("grab_particles.L.blank.corrected" = particles.L.blank.corrected,
                              "sampleID" = "sampleID_closestDate"),
                     by = c("sampleID")) %>% 
  #annotate wet/dry
  mutate(season = case_when(grepl("Nov|Dec|Jan|Feb|Mar", sampleID, ignore.case = TRUE) ~ "wet",
                            grepl("Aug|Sep", sampleID, ignore.case = TRUE) ~ "dry"))

#view matched data
match_plot_closest_season <- closestMatches %>% 
  drop_na(grab_particles.L.blank.corrected) %>% 
  filter(grab_particles.L.blank.corrected > 0) %>% #remove 0's that shouldn't belong
  ggplot(aes(x = particles.L.blank.corrected, y = grab_particles.L.blank.corrected, color = season))+
  geom_point()+
  geom_smooth(method = "lm", se=FALSE, formula = my.formula) +
   stat_poly_eq(formula = my.formula, 
                aes(label = paste(..eq.label.., ..rr.label.., ..p.value.label.., sep = "~~~")), 
                parse = TRUE) +         
  scale_x_log10(name = "Manta Trawl blank-corrected particles/L",
                breaks = scales::trans_breaks("log10", function(x) 10^x),
        labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  scale_y_log10(name = "1L-grab blank-corrected particles/L") +
  theme.type +
     theme(legend.position = c(0.7,0.92),
        legend.title = element_blank(),
        legend.background = element_blank(),
        legend.text = element_text(size = 12))

#view matched data overall
match_plot_closest <- closestMatches %>% 
  drop_na(grab_particles.L.blank.corrected) %>% 
  filter(grab_particles.L.blank.corrected > 0) %>% #remove 0's that shouldn't belong
  ggplot(aes(x = particles.L.blank.corrected, y = grab_particles.L.blank.corrected))+
  geom_point()+
  geom_smooth(method = "lm", se=FALSE, formula = my.formula) +
   stat_poly_eq(formula = my.formula, 
                aes(label = paste(..eq.label.., ..rr.label.., ..p.value.label.., sep = "~~~")), 
                parse = TRUE) +         
  scale_x_log10(name = "Manta Trawl blank-corrected particles/L",
                breaks = scales::trans_breaks("log10", function(x) 10^x),
        labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  scale_y_log10(name = "1L-grab blank-corrected particles/L") +
  theme.type +
     theme(legend.position = c(0.7,0.92),
        legend.title = element_blank(),
        #legend.background = element_rect(color = "black", fill = "white", linetype = "solid"),
        legend.text = element_text(size = 12))

ggarrange(match_plot_closest_season,match_plot_closest)
```
```{r}
match_plots <- ggarrange(match_plot_true_overall, match_plot_true_season,
          match_plot_closest, match_plot_closest_season,
          labels = c("A", "B", "C", "D"),
          ncol = 2,
          nrow = 2)

match_plots

ggsave(plot = match_plots,
       filename = "match_plots.jpeg",
       path = "output/figures/", 
       width = 11, height = 9, units = "in",
       bg = "white",
       dpi = 300)
```

## Rbind
```{r}

grab_with_dates_new <- grab_with_dates %>% 
  mutate(sampleID = paste(Station.Code, newDates, "grab")) %>% 
  dplyr::select(-c(Station.Code, newDates, particle_count, sample_volume_L, Date_string, match, needs_fixing, sampleID_closestDate)) %>% 
  rename("latitude" = "latitude_grab",
         "longitude" = "longitude_grab")

#bind
sfBay2 <- rbind(sfBay_noGrab, grab_with_dates_new) %>% 
  #annotate wet/dry
  mutate(season = case_when(grepl("Nov|Dec|Jan|Feb|Mar", sampleID, ignore.case = TRUE) ~ "wet",
                            grepl("Aug|Sep", sampleID, ignore.case = TRUE) ~ "dry"))
```

## Plastic particle correction
10 particles were analyzed for every color/morphology combo. 68% of particles analyzed by Raman/FTIR were plastic in surface water and 23% in fish samples were plastic.

Site-specific polymer percentages are reported in Table S18 of Zhu et al (2021) https://pubs.acs.org/doi/10.1021/acsestwater.0c00292?goto=supporting-info 
Data from this table were imported into excel and are used to correct for plastic percentages in locaiton-specific compartments below.

### Derive correction factors
```{r}
#read in table S18
site_polymer_percentages <-  readxl::read_excel("data/grab_with_dates.xlsx", sheet = "relative_abundances", na = "N/A") %>% mutate_if(is.character, as.factor)

#long-wise
long_polymer <- site_polymer_percentages %>% 
  pivot_longer(-c(Sample.Type, Polymer), names_to = "location", values_to = "proportion") %>% 
  drop_na()

#ensure adds up to 100%
long_polymer %>% 
  group_by(location, Sample.Type) %>% 
  summarize(sum(proportion))
```

```{r}
#collapse categories
summary_proportions <- long_polymer %>% 
  mutate(general = case_when(
    grepl("Unknown", Polymer, ignore.case = TRUE) ~ "unknown",
    grepl("anthropogenic", Polymer, ignore.case = TRUE) ~ "unknown",
    grepl("natural", Polymer, ignore.case = TRUE) ~ "natural",
    Polymer == "Wool" ~ "natural",
    Polymer == "Cotton" ~ "natural",
    Polymer == "Cellulosic" ~ "natural",
    Polymer == "Glass" ~ "anthropogenic (not plastic)",
    Polymer == "Asphalt" ~ "anthropogenic (not plastic)",
    Polymer == "Not Characterized" ~ "Not Characterized"
    )) %>% 
  replace_na(list(general = "plastic")) %>% 
  group_by(general, location, Sample.Type) %>% 
  summarize(freq_total = sum(proportion))
  
summary_proportions %>%  DT::datatable()
```

Collapse further to obtain plastic percentages by matrix x location
```{r}
#recode
plastic_proportions <- summary_proportions %>% 
  filter(general == "plastic") %>% 
  mutate(proportion = freq_total/100) %>% 
  mutate(location_fix = case_when(
    location == "CentralBay" ~ "Central Bay",
    location == "LowerSouthBay" ~ "Lower South Bay",
    location == "NMS" ~ "National Marine Sanctuary",
    location == "NorthBay" ~ "North Bay",
    location == "SouthBay" ~ "South Bay",
    location == "TomalesBay" ~ "Tomales Bay")) %>% 
  mutate(locationMatrix = paste(location_fix, Sample.Type))  %>% 
  ungroup() 
  

#view
plastic_proportions
```
#### Site-specific Polymer Proportion Figure
```{r}
propotion_heatmap <- plastic_proportions %>% 
  dplyr::select(c(location_fix, proportion, Sample.Type)) %>% 
  #filter(location_fix %in% c("Central Bay", "Lower South Bay")) %>% 
  ggplot(aes(y = location_fix, x = Sample.Type, fill = proportion)) +
  geom_tile() +
  scale_fill_viridis(name = "Plastic % of \nSub-Sampled \nParticles",
                     discrete = FALSE,
                     limits = c(0,1),
                     labels = scales::percent_format(scale = 100)) +
  ylab("Location in SF Bay") +
  xlab("Compartment") +
  theme.type +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        panel.grid.major = element_blank(),
    panel.grid.minor = element_blank())

propotion_heatmap
```


#### General proportions
Polymer percentages are not available for all locations, so general proportions must be derived
```{r}
general_proportions <- plastic_proportions %>% 
  group_by(Sample.Type) %>% 
  summarize(ave.prop = mean(proportion), sd.prop = sd(proportion))

general_proportions

general_proportions_graph <- general_proportions %>% 
  ggplot(aes(x = ave.prop, y = Sample.Type, fill = Sample.Type)) +
  geom_col() +
  geom_errorbarh(aes(xmax = ave.prop + sd.prop, xmin = ave.prop - sd.prop)) +
  scale_x_continuous(name = "Plastic % of Sub-Sampled Particles (mean +- SD)",
                     limits = c(0,1),
                     labels = scales::percent_format(scale = 100)) +
  scale_fill_futurama() +
  theme.type +
  theme(legend.position = "none",
        axis.title.y = element_blank())

general_proportions_graph
```
```{r}
proportions_arranged <- ggarrange(propotion_heatmap,general_proportions_graph,
          labels = c("A", "B"),
          ncol = 1,
          nrow = 2)

proportions_arranged

ggsave(plot = proportions_arranged,
       filename = "proportions_arranged.jpeg",
       path = "output/figures/", 
       width = 10, height = 6, units = "in",
       bg = "white",
       dpi = 300)
```


#### Export table
```{r}
final_proportions <- rbind(plastic_proportions %>% 
        dplyr::select(c(locationMatrix, proportion)),
                      general_proportions %>% 
                        mutate(locationMatrix = paste("general", Sample.Type)) %>% 
                        rename(proportion = ave.prop) %>% 
                        dplyr::select(c(locationMatrix, proportion))
      )

final_proportions

## export pretty table
pretty_proportions <- left_join(final_proportions, plastic_proportions, by = "locationMatrix") %>%
  dplyr::select(c(locationMatrix,Sample.Type, location_fix, proportion.x))

write.csv(pretty_proportions,
          "output/data/final_plastic_proportion.csv"
          )
```

### Apply correciton factors

```{r}
##recode missing levels into generic (NA)
sfBay2_recode <- sfBay2 %>% 
  mutate(locationNew = case_when(
    general.location == "Central Bay" ~ "Central Bay",
    general.location == "South Bay" ~ "South Bay",
    general.location == "Lower South Bay" ~ "Lower South Bay",
    general.location == "National Marine Sancturay" ~ "National Marine Sanctuary",
    general.location == "Tomales Bay" ~ "Tomales Bay",
    general.location == "Treasure Island" ~ "general",
    general.location == "SPB" ~ "general",
    general.location == "SC" ~ "general",
    general.location == "SUB" ~ "general",
    general.location == "SOSL" ~ "general")) %>% 
  #cleanup
  replace_na(list(locationNew = "general")) %>% 
   #recode matrices
  mutate(matrix = case_when(
    sample.matrix == "fish" ~ "Fish",
    sample.matrix == "sediment" ~ "Sediment",
    sample.matrix.specific == "stormwater" ~ "Storm",
    sample.matrix.specific == "surface water" ~ "Surface",
    sample.matrix.specific == "wastewater" ~ "WWTP")) %>% 
    #ID
  mutate(locationMatrix = factor(paste(locationNew, matrix)))

sfBay2_recode
```


```{r}
#join tables
sfBay2_joined <- left_join(sfBay2_recode, final_proportions, by = "locationMatrix")

sfBay2_joined 
```


Cleanup and apply general correction factors when site-specific data were unavailable
```{r}
sfBay3 <- sfBay2_joined %>% 
  mutate(particles.L.blank.corrected.particle.corrected = particles.L.blank.corrected * proportion,
         particles.fish.blank.corrected.particle.corrected = particles.fish.blank.corrected * proportion,
         particles.kg.blank.corrected.particle.corrected = particles.kg.blank.corrected * proportion)
```


## Size-based Correction
Given an upper limit (UL) and lower limit (LL) of the measured and default size range, a dimensionless correction factor ($CF_{meas}$) for measured environmental concentrations may be calculated, which rescales the measured number concentrations for a certain size range to the number concentration for the microplastics default (D) size range (e.g. 1 to 5,000 um) (Koelmans et al 2020). Coefficients for the environmental-specific compartment for the power law distribution for length (L) with slope $\alpha_L$ is from Table S4 of Kooi et al (2021). 

$CF_{Meas} = \frac{L^{1-a}_{UL,D} - L^{1-a}_{LL,D}}{L^{1-a}_{UL,M} - L^{1-a}_{LL,M}}$

```{r}
# Align Data

#function to derive correction factor (CF) from Koelmans et al (equation 2)
CFfnx = function(a = alpha, #default alpha from Koelmans et al (2020)
                 x2D = x2D_set, #set detault values to convert ranges to (1-5,000 um) #5mm is upper defuault 
                 x1D = x1D_set, #1 um is lower default size
                 x2M, x1M){
  
  CF = (x2D^(1-a)-x1D^(1-a))/(x2M^(1-a)-x1M^(1-a))
  
  return(CF)
}
#verify it works (expected answer is 40.37)
#CFfnx(x1M = 333, x2M = 5000)


# correct aquatic concentrations for SF Bay
sfBay_aligned <- sfBay3 %>% 
  mutate(CF = case_when(
    sample.matrix.specific == "surface water" ~ CFfnx(a = alpha.marine, x1M = x1M, x2M = x2M, x1D = x1D_set, x2D = x2D_set),
   sample.matrix.specific == "sediment" ~ CFfnx(a = alpha.sediment, x1M = x1M, x2M = x2M, x1D = x1D_set, x2D = x2D_set),
   sample.matrix.specific == "wastewater" ~ CFfnx(a = alpha.wastewater, x1M = x1M, x2M = x2M, x1D = x1D_set, x2D = x2D_set),
   sample.matrix.specific == "stormwater" ~ CFfnx(a = alpha.stormwater, x1M = x1M, x2M = x2M, x1D = x1D_set, x2D = x2D_set),
   sample.matrix == "fish" ~ CFfnx(a = alpha.fish, x1M = x1M, x2M = x2M, x1D = x1D_set, x2D = x2D_set),)) %>% 
  mutate(particle.L.master = particles.L.blank.corrected.particle.corrected * CF,
         particle.fish.master = particles.fish.blank.corrected.particle.corrected * CF,
         particles.kg.master = particles.kg.blank.corrected.particle.corrected * CF) %>% 
  rename(unaligned.particle.L.master = particles.L.blank.corrected.particle.corrected) %>% 
  #filter(unaligned.particle.L.master > 0) %>%  #remove blanks. should convert to 1/2 LOQ...
  mutate(source = "SFEI") %>% 
  mutate(Reference = "Zhu et. al 2021") %>% 
  rename(Sampling.location = general.location) %>% 
  #dplyr::select(-c(particles.kg.blank.corrected,
   #                particles.fish.blank.corrected)) %>% 
  mutate(compartment = case_when(
    System == "Lake" ~ "freshwater",
    System == "River" ~ "freshwater",
    System == "Estuary" ~ "marine",
    System == "Ocean" ~ "marine",
  )) %>% 
  mutate(Conc = particle.L.master) %>% 
  mutate_if(is.character, as.factor)
```




# Occurence ANalysis

### Boxplot SFEI
```{r}
SFEI_mesh_matrix <- sfBay_aligned %>% 
  filter(source == "SFEI") %>% 
  #filter(sample.matrix.specific == "surface water") %>% 
  drop_na(particle.L.master) %>% 
  ggplot(aes(x = sample.matrix.specific))+
  #aligned
  geom_boxplot(aes(y = particle.L.master),
               alpha = 0.4, notch = TRUE) +
  geom_jitter(aes(y = particle.L.master, color = Sampling.apparatus),
              width = 0.15) +
  #unaligned
 # geom_boxplot(aes(y = unaligned.particle.L.master),
  #             alpha = 0.4, notch = TRUE) +
  geom_jitter(aes(y = unaligned.particle.L.master, color = Sampling.apparatus),
              alpha = 0.3,
              width = 0.15) +

  scale_color_d3(name = "Sampling Apparatus") +
  #scale_color_manual(name = "Sampling Apparatus",values = wes_palette("Darjeeling1"))+
   # geom_hline(yintercept = Threshold1, linetype = 'dashed', color = 'green', size = 1) +
   # geom_hline(yintercept = Threshold2, linetype = 'dashed', color = 'yellow', size = 1) +
   # geom_hline(yintercept = Threshold3, linetype = 'dashed', color = 	'orange', size = 1) +
   # geom_hline(yintercept = Threshold4, linetype = 'dashed', color = 	'red', size = 1) +
  # geom_text(label = "Threshold 1", color = 'green', x = Threshold1, y = 0.15, size = 6)+
  # geom_text(label = "Threshold 2", color = 'yellow', x = Threshold2, y = 0.22, size = 6)+
  # geom_text(label = "Threshold 3", color = 'orange', x = Threshold3, y = 0.35, size = 6)+
  # geom_text(label = "Threshold 4", color = 'red', x = Threshold4, y = 0.45, size = 6)+
  scale_y_log10(breaks = scales::trans_breaks("log10", function(y) 10^y),labels = comma_signif)+
  annotation_logticks(sides = "b")+ #log scale rick marks on bottom
  ylab(paste0("Particles/L (" ,x1D_set, " to ", x2D_set, " μm)"))+
  theme.type +
  labs(title = "San Francisco Bay Surface Water Marine Microplastics Concentrations",
       subtitle = paste("Particles/L corrected to:",x1D_set, "to", x2D_set, "um"),
      # caption = paste("Concentration data from Zhu et al (2021): 29 sampling locations, n = 136; corrected for size ranges. Alpha = ",alpha.marine)
      )+
  theme(
    plot.title = element_text(hjust = 0.5, size = 18),
        plot.subtitle = element_text(hjust = 0.5, size = 14),
    axis.title.x = element_blank())

SFEI_mesh_matrix
```

# SFBay Exceedances
```{r}
######REMOVE IF FIXING JOIN ABOVE!!!###
sfBay_new <- sfBay_aligned

#make new dataframe to plot both histograms together
sampleSimpleSFEI <- sfBay_new %>%
  filter(source == "SFEI") %>% 
  filter(sample.matrix.specific == "surface water") %>% 
  drop_na(Conc) %>% 
  droplevels()

#make new dataframe to plot both histograms together
dfSFEI <- rbind(sampleSimpleSFEI)#,food.dilution.simple)

#calculate exceedance
dfSFEI_exceedance <- dfSFEI %>% 
  mutate(aboveThreshold = factor(case_when(
    Conc < Threshold1 ~ "below Threshold 1",
    Conc >= Threshold1 & Conc < Threshold2 ~ "above Threshold 1",
    Conc >= Threshold2 & Conc < Threshold3 ~ "above Threshold 2",
    Conc >= Threshold3 & Conc < Threshold4 ~ "above Threshold 3",
    Conc >= Threshold4 ~ "above Threshold 4"
  )))

#give summary stat for exceedance
exceedance <- dfSFEI_exceedance  %>%
  filter(Sample.Type == "sample") %>% 
  dplyr::select(c(Conc, aboveThreshold)) %>%
  group_by(aboveThreshold) %>%
  dplyr::summarize(n = n()) %>% 
  mutate(rel.freq = paste0(round(100 * n/sum(n), 0), "%"))

exceedance
```
#### Sensitivity Analysis based on Alignments
<!-- Table S4 from Kooi et al (2021) includes the mean +- standard deviation for power law exponents. To test the sensitivity of this risk characterization based on alignments, a range of power law exponents for particle length are used within the upper and lower 99% of the data from which the power law exponent was derived. For marine surface water, the alpha value of 2.07 has a standard deviation of 0.03 (Kooi et al 2021). The mean plus or minus one, two, and three standard deviations are used to calculate risk exceedances to test sensitivity. -->

probability_distributions.Rmd determines the size power law for marine surface waters in SF Bay of 1.89 +- 0.084 which is used to estiamte the uncertainty here

##### Align
```{r}
# alpha.marine.plus.one <- alpha.marine + alpha.marine.sd
# alpha.marine.plus.two <- alpha.marine + (2 * alpha.marine.sd)
# alpha.marine.plus.three <- alpha.marine + (3 * alpha.marine.sd)
# alpha.marine.minus.one <- alpha.marine - alpha.marine.sd
# alpha.marine.minus.two <- alpha.marine - (2 * alpha.marine.sd)
# alpha.marine.minus.three <- alpha.marine - (3 * alpha.marine.sd)

#create dataframe with PDFs derived in probability_distributions.Rmd
alignment_factors <- data.frame("matrix" = c("Surface", "Fish", "Storm", "WWTP", "Sediment"),
                                "alpha" = c(alpha.marine, alpha.fish, alpha.stormwater, alpha.wastewater, alpha.sediment),
                                "alpha.se" = c(alpha.marine.sd, alpha.fish.sd, alpha.stormwater.sd, alpha.wastewater.sd, alpha.sediment.sd)) %>% 
  mutate(alpha.upper.68 = alpha + alpha.se,
         alpha.lower.68 = alpha - alpha.se,
         alpha.upper.95 = alpha + (1.96*alpha.se),
         alpha.lower.95 = alpha - (1.96*alpha.se),
         alpha.upper.99 = alpha + (3*alpha.se),
         alpha.lower.99 = alpha - (3*alpha.se))

alignment_factors
```

```{r}
sfBay_new2 <- left_join(sfBay_new, alignment_factors, by = "matrix")

#align data for different scenarios
sensitivity <- sfBay_new2 %>%
  #derive correction factors
  mutate(CF.upper.68 = CFfnx(a = alpha.upper.68, x1M = x1M, x2M = x2M, x1D = x1D_set, x2D = x2D_set),
         CF.upper.95 = CFfnx(a = alpha.upper.95, x1M = x1M, x2M = x2M, x1D = x1D_set, x2D = x2D_set),
         CF.upper.99 = CFfnx(a = alpha.upper.99, x1M = x1M, x2M = x2M, x1D = x1D_set, x2D = x2D_set),
         CF.lower.68 = CFfnx(a = alpha.lower.68, x1M = x1M, x2M = x2M, x1D = x1D_set, x2D = x2D_set),
         CF.lower.95 = CFfnx(a = alpha.lower.95, x1M = x1M, x2M = x2M, x1D = x1D_set, x2D = x2D_set),
         CF.lower.99 = CFfnx(a = alpha.lower.99, x1M = x1M, x2M = x2M, x1D = x1D_set, x2D = x2D_set)) %>%
  #apply correction fcators
  mutate(conc.upper.68 = case_when(sample.matrix == "water" ~ CF.upper.68 * unaligned.particle.L.master,
                                   sample.matrix == "sediment" ~ CF.upper.68 * particles.kg.blank.corrected.particle.corrected,
                                   sample.matrix == "fish" ~ CF.upper.68 * particles.fish.blank.corrected.particle.corrected),
         conc.upper.95 =  case_when(sample.matrix == "water" ~ CF.upper.95 * unaligned.particle.L.master,
                                   sample.matrix == "sediment" ~ CF.upper.95 * particles.kg.blank.corrected.particle.corrected,
                                   sample.matrix == "fish" ~ CF.upper.95 * particles.fish.blank.corrected.particle.corrected),
         conc.upper.99 =  case_when(sample.matrix == "water" ~ CF.upper.99 * unaligned.particle.L.master,
                                   sample.matrix == "sediment" ~ CF.upper.99 * particles.kg.blank.corrected.particle.corrected,
                                   sample.matrix == "fish" ~ CF.upper.99 * particles.fish.blank.corrected.particle.corrected),
         ## lower intervals
         conc.lower.68 = case_when(sample.matrix == "water" ~ CF.lower.68 * unaligned.particle.L.master,
                                   sample.matrix == "sediment" ~ CF.lower.68 * particles.kg.blank.corrected.particle.corrected,
                                   sample.matrix == "fish" ~ CF.lower.68 * particles.fish.blank.corrected.particle.corrected),
         conc.lower.95 =  case_when(sample.matrix == "water" ~ CF.lower.95 * unaligned.particle.L.master,
                                   sample.matrix == "sediment" ~ CF.lower.95 * particles.kg.blank.corrected.particle.corrected,
                                   sample.matrix == "fish" ~ CF.lower.95 * particles.fish.blank.corrected.particle.corrected),
         conc.lower.99 =  case_when(sample.matrix == "water" ~ CF.lower.99 * unaligned.particle.L.master,
                                   sample.matrix == "sediment" ~ CF.lower.99 * particles.kg.blank.corrected.particle.corrected,
                                   sample.matrix == "fish" ~ CF.lower.99 * particles.fish.blank.corrected.particle.corrected)
  )

sensitivity
                                   
```

###### EXPORT DATA
```{r}
write.csv(sensitivity,
          "output/data/final_aligned_dataset.csv"
          )
```

###Export table showing correction factors
```{r}
CF_table <- sensitivity %>% 
  group_by(Sampling.apparatus, matrix) %>% 
  summarize(mesh_size = mean(x1M),
            CF = round(mean(CF),2), 
            CF.lower.95 = round(mean(CF.lower.95),2),
            CF.upper.95 = round(mean(CF.upper.95),2))

write.csv(CF_table,
          "output/data/CF_table.csv")

CF_table
```

#### Compare to thresholds
##### All surface water samples
```{r}
#count samples
surface.count <- sensitivity %>% 
  filter(source == "SFEI") %>% 
  filter(sample.matrix.specific == "surface water") %>% 
  summarize(n())

sensitivity.analysis <- sensitivity %>% 
  filter(source == "SFEI") %>% 
  filter(sample.matrix.specific == "surface water") %>% 
  #just select concentrations
  dplyr::select(c(Conc, conc.upper.68, conc.upper.95, conc.upper.99, conc.lower.68, conc.lower.95, conc.lower.99)) %>% 
  #make long data
  pivot_longer(everything()) %>% 
  mutate(aboveThreshold = factor(case_when(
    value < Threshold1_food ~ "below Threshold 1",
    value >= Threshold1_food & value < Threshold2_food ~ "above Threshold 1",
    value >= Threshold2_food & value < Threshold3_food ~ "above Threshold 2",
    value >= Threshold3_food & value < Threshold4_food ~ "above Threshold 3",
    value >= Threshold4_food ~ "above Threshold 4"
  ))) %>% 
 group_by(aboveThreshold, name) %>%
  dplyr::summarize(n = n()) %>% 
  mutate(rel.freq = paste0(round(100 *(n/surface.count[1,]),1),"%")) %>% 
  pivot_wider(names_from = "name", values_from = c("n", "rel.freq")) %>% 
  mutate(aboveThreshold = factor(aboveThreshold, levels = c("below Threshold 1", "above Threshold 1", "above Threshold 2", "above Threshold 3", "above Threshold 4"))) %>% 
  arrange(aboveThreshold)

sensitivity.analysis 
```

###### EXPORT EXCEEDANCES
```{r}
write.csv(sensitivity.analysis ,
          "output/data/surface_water_exceedances_sensitivity_analysis.csv"
          )
```

###### Sensitivity Plot
```{r}
#ECDF by System
sfBayECDF_sensitivity <- sensitivity %>% 
  filter(source == "SFEI") %>% 
  filter(sample.matrix.specific == "surface water") %>% 
  filter(particle.L.master > 0) %>% 
  #just select concentrations
  dplyr::select(c(Conc, conc.upper.68, conc.upper.95, conc.upper.99, conc.lower.68, conc.lower.95, conc.lower.99)) %>% 
  #make long data
  pivot_longer(everything()) %>% 
  mutate(name = as.factor(name)) %>% 
  ggplot() +
 # stat_ecdf(aes(x = value, color = name),
  #          geom = "point", size = 1, alpha = 0.5) +
  stat_ecdf(aes(x = value, color = name),geom = "step", linetype = 'solid', alpha = 0.7, size = 9) +
  #color
  scale_color_manual(name = "Alignment Uncertanties",
                     values = c("Conc" = "#e8ffff",
                                "conc.lower.68" = "#bfe6ff",
                                "conc.upper.68" = "#bfe6ff",
                                "conc.lower.95" = "#8cd3ff",
                                "conc.upper.95" = "#8cd3ff",
                                "conc.lower.99" = "#009dff",
                                "conc.upper.99" = "#009dff"),
                     labels = c("Mean", 
                                "68th Percentile",
                                "68th Percentile",
                                "95th Percentile",
                                "95th Percentile",
                                "99.7th Percentile",
                                "99.7th Percentile")) +
  # ##Food Dilution thresholds #
  # geom_vline(xintercept = Threshold1_food, linetype = 'solid', color = "#85a17d", size = 1) +
  # geom_text(label = "Food Dilution T1", color = "#85a17d" , x = Threshold1_food, y = 0.10, size = 5)+
  geom_vline(xintercept = Threshold2_food, linetype = 'dashed', color = "#ebbb38", size = 1.5) +
  geom_text(label = "Food Dilution T2", color = "#ebbb38" , x = Threshold2_food, y = 0.15, size = 6)+
  # geom_vline(xintercept = Threshold3_food, linetype = 'dashed', color = "#fd8060", size = 1) +
  # geom_text(label = "Food Dilution T3", color = "#fd8060" , x = Threshold3_food, y = 0.20, size = 5)+
   geom_vline(xintercept = Threshold4_food, linetype = 'dashed', color = "#E84258", size = 1.5) +
  geom_text(label = "Food Dilution T4", color = "#E84258",  x = Threshold4_food, y = 0.25, size = 6)+
  ## Food dilution 95% CI's ##
  # geom_vline(xintercept = Threshold2_food_lcl, linetype = 'dashed', color = "#ebbb38", size = 1) +
  # geom_vline(xintercept = Threshold2_food_hcl, linetype = 'dashed', color = "#ebbb38", size = 1) +
  # geom_vline(xintercept = Threshold3_food_lcl, linetype = 'dashed', color = "#fd8060", size = 1.5) +
  # geom_vline(xintercept = Threshold3_food_hcl, linetype = 'dashed', color = "#fd8060", size = 1.5) +
  # geom_vline(xintercept = Threshold4_food_lcl, linetype = 'dashed', color = "#E84258", size = 1.5) +
  # geom_vline(xintercept = Threshold4_food_hcl, linetype = 'dashed', color = "#E84258", size = 1.5) +
  
  ## Food dilution 95% CI's ribbons ##
  annotate("rect", xmin = Threshold2_food_lcl, xmax = Threshold2_food_hcl, ymin = 0, ymax = 1, fill = "#fd8060", alpha = 0.2, color = "#fd8060", linetype = "dotted")+
  #annotate("rect", xmin = Threshold3_food_lcl, xmax = Threshold3_food_hcl, ymin = 0, ymax = 1, fill = "#fd8060", alpha = 0.2)+
  annotate("rect", xmin = Threshold4_food_lcl, xmax = Threshold4_food_hcl, ymin = 0, ymax = 1, fill = "#E84258", alpha = 0.2,
           color = "#fd8060", linetype = "dotted")+
  
    ylab("Cumulative Density") +
  xlab("Surface Water Particles/L (aligned to 1 to 5,000 µm)") +
  #xlab(paste0("Particles/L (" ,x1D_set, " to ", x2D_set, "um)"))+
  scale_y_continuous(labels = scales::percent)+
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x),labels = comma_signif)+
  #annotation_logticks(sides = "b")+ #log scale rick marks on bottom
  theme.type +
  theme(legend.title = element_blank(),
        legend.position = "none")
  #labs(title = "Global Surface Water Marine Microplastics Concentrations",
   #    subtitle = paste("Particles/L corrected to:",x1D_set, "to", x2D_set, "um"),
    #   caption = paste("Concentration data from Adams et al (2019): 23 studies, 57 sampling locations, n = 377; corrected for size ranges. Alpha = ",alpha))
 
sfBayECDF_sensitivity
```
```{r}
ggsave(plot = sfBayECDF_sensitivity,
       filename = "sfBayECDF_sensitivity.jpeg",
       path = "output/figures/", 
       width = 10, height = 6, units = "in",
       bg = "white",
       dpi = 300)
```

##### MANTA only
```{r}
#count samples
manta.count <- sensitivity %>% 
  filter(source == "SFEI") %>% 
  filter(sample.matrix.specific == "surface water") %>% 
  filter(Sampling.apparatus == "Manta Trawl") %>%
  summarize(n())


sensitivity.analysis.manta <- sensitivity %>% 
  filter(source == "SFEI") %>% 
  filter(sample.matrix.specific == "surface water") %>% 
  filter(Sampling.apparatus == "Manta Trawl") %>%
  #just select concentrations
  dplyr::select(c(Conc, conc.upper.68, conc.upper.95, conc.upper.99, conc.lower.68, conc.lower.95, conc.lower.99)) %>% 
  #make long data
  pivot_longer(everything()) %>% 
  mutate(aboveThreshold = factor(case_when(
    value < Threshold1_food ~ "below Threshold 1",
    value >= Threshold1_food & value < Threshold2_food ~ "above Threshold 1",
    value >= Threshold2_food & value < Threshold3_food ~ "above Threshold 2",
    value >= Threshold3_food & value < Threshold4_food ~ "above Threshold 3",
    value >= Threshold4_food ~ "above Threshold 4"
  ))) %>% 
  group_by(aboveThreshold, name) %>%
  dplyr::summarize(n = n()) %>% 
  mutate(rel.freq = paste0(round(100 *(n/manta.count[1,]),1),"%")) %>% 
  pivot_wider(names_from = "name", values_from = c("n", "rel.freq")) %>% 
  mutate(aboveThreshold = factor(aboveThreshold, levels = c("below Threshold 1", "above Threshold 1", "above Threshold 2", "above Threshold 3", "above Threshold 4"))) %>% 
  arrange(aboveThreshold)
  

sensitivity.analysis.manta
```

###### EXPORT EXCEEDANCES
```{r}
write.csv(sensitivity.analysis.manta ,
          "output/data/surface_water_exceedances_sensitivity_analysis_manta.csv"
          )
```


##### Manta vs. Grab

```{r}
#ECDF by System
sfBayECDF_sensitivity <- sensitivity %>% 
  filter(source == "SFEI") %>% 
  filter(sample.matrix.specific == "surface water") %>% 
  filter(particle.L.master > 0) %>% 
  #just select concentrations
  #dplyr::select(c(Conc, conc.plus1, conc.plus2, conc.plus3, conc.minus1, conc.minus2, conc.minus3)) %>% 
  #make long data
 # pivot_longer(everything()) %>% 
  #mutate(name = as.factor(name)) %>% 
  ggplot() +
 # stat_ecdf(aes(x = value, color = name),
  #          geom = "point", size = 1, alpha = 0.5) +
  stat_ecdf(aes(x = Conc, color = Sampling.apparatus),geom = "step", linetype = 'solid', alpha = 0.7, size = 2.5) +
  #color
  # scale_color_manual(name = "Alignment Uncertanties",
  #                    values = c("Conc" = "#e8ffff",
  #                               "conc.minus1" = "#bfe6ff",
  #                               "conc.plus1" = "#bfe6ff",
  #                               "conc.minus2" = "#8cd3ff",
  #                               "conc.plus2" = "#8cd3ff",
  #                               "conc.minus3" = "#009dff",
  #                               "conc.plus3" = "#009dff"),
  #                    labels = c("Mean", 
  #                               "68th Percentile",
  #                               "68th Percentile",
  #                               "95th Percentile",
  #                               "95th Percentile",
  #                               "99.7th Percentile",
  #                               "99.7th Percentile")) +
  # ##Food Dilution thresholds
  geom_vline(xintercept = Threshold1_food, linetype = 'dashed', color = "#66a182", size = 1.3) +
  geom_vline(xintercept = Threshold4_food, linetype = 'dashed', 
             color = "#d1495b",
             size = 1.3) +
  geom_text(label = "Food Dilution T1", color = "#66a182" , x = Threshold1_food, y = 0.15, size = 6)+
   geom_text(label = "Food Dilution T4", color = "#d1495b", 
            x = Threshold4_food,
            y = 0.25, size = 6)+
  ###Oxidative Stress thresholds
  geom_vline(xintercept = Threshold1_oxidative.stress, linetype = 'dashed',
             color = "#66a182",#"#00798c",
             size = 1.3) +
  geom_vline(xintercept = Threshold4_oxidative.stress, linetype = 'dashed',
             color = "#d1495b",
             size = 1.3) +
  geom_text(label = "Oxidative Stress T1", color = "#66a182",#'#edae49',
            x = Threshold1_oxidative.stress - 0.8 * Threshold1_oxidative.stress, 
            y = 0.45, size = 6) +
  geom_text(label = "Oxidative Stress T4", color = "#d1495b", x =
              Threshold4_oxidative.stress - 0.8 * Threshold4_oxidative.stress, 
            y = 0.55, size = 6)+
    ylab("Cumulative Density") +
  xlab("Particles/L") +
  #xlab(paste0("Particles/L (" ,x1D_set, " to ", x2D_set, "um)"))+
  scale_y_continuous(labels = scales::percent)+
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x),labels = comma_signif)+
  #annotation_logticks(sides = "b")+ #log scale rick marks on bottom
  theme.type #+
 # theme(legend.title = element_blank(),
  #      legend.position = "none")
  #labs(title = "Global Surface Water Marine Microplastics Concentrations",
   #    subtitle = paste("Particles/L corrected to:",x1D_set, "to", x2D_set, "um"),
    #   caption = paste("Concentration data from Adams et al (2019): 23 studies, 57 sampling locations, n = 377; corrected for size ranges. Alpha = ",alpha))
 
sfBayECDF_sensitivity
```
##### Wet Vs Dry

```{r}
#ECDF by System
sfBayECDF_wetDry <- sfBay_new %>% 
  filter(source == "SFEI") %>% 
  filter(particle.L.master > 0) %>% 
  filter(sample.matrix.specific == "surface water"#,
         #Sampling.apparatus == "Manta Trawl"
         ) %>% 
  ggplot(aes(color = interaction(season, Sampling.apparatus, sep = "-"))) +
  #aligned
  stat_ecdf(aes(x = particle.L.master),geom = "step", linetype = 'solid', alpha = 0.7, size = 2.5) +
  #unaligned
  #stat_ecdf(aes(x = unaligned.particle.L.master),geom = "step", linetype = 'solid', alpha = 0.2, size = 2.5) +
  #color
  scale_color_manual(values = hcl(h = c(20,190,65,245),c = 100, l = 65)) +
  #scale_alpha_manual(name = "alignment",
   #                 values = c(0.2,1)) +
  geom_vline(xintercept = Threshold1_food, linetype = 'dashed', color = "#85a17d", size = 1) +
  geom_text(label = "Food Dilution T1", color = "#85a17d" , x = Threshold1_food, y = 0.10, size = 5)+
  geom_vline(xintercept = Threshold2_food, linetype = 'dashed', color = "#ebbb38", size = 1) +
  geom_text(label = "Food Dilution T2", color = "#ebbb38" , x = Threshold2_food, y = 0.15, size = 5)+
  geom_vline(xintercept = Threshold3_food, linetype = 'dashed', color = "#fd8060", size = 1) +
  geom_text(label = "Food Dilution T3", color = "#fd8060" , x = Threshold3_food, y = 0.20, size = 5)+
  geom_vline(xintercept = Threshold4_food, linetype = 'dashed', color = "#E84258", size = 1) +
  geom_text(label = "Food Dilution T4", color = "#E84258",  x = Threshold4_food, y = 0.25, size = 5)+
  #Aesthetics  
  ylab("Cumulative Density") +
  labs(color = "Season - Sampling technique") +
  xlab("Particles/L (1 to 5,000 µm)") +
  #xlab(paste0("Particles/L (" ,x1D_set, " to ", x2D_set, "um)"))+
  scale_y_continuous(labels = scales::percent)+
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x),labels = comma_signif)+
  #annotation_logticks(sides = "b")+ #log scale rick marks on bottom
  theme.type +
  theme(legend.position = "top")
  #labs(title = "Global Surface Water Marine Microplastics Concentrations",
   #    subtitle = paste("Particles/L corrected to:",x1D_set, "to", x2D_set, "um"),
    #   caption = paste("Concentration data from Adams et al (2019): 23 studies, 57 sampling locations, n = 377; corrected for size ranges. Alpha = ",alpha))
 
sfBayECDF_wetDry
```

```{r}
ggsave(plot = sfBayECDF_wetDry,
       filename = "sfBayECDF_wetDry.jpeg",
       path = "output/figures/", 
       width = 10, height = 6, units = "in",
       bg = "white",
       dpi = 300)
```

### Risk Characterization Histogram (SFBay)
```{r}
#generate plot
dfSFEI_exceedance %>% 
 # filter(Conc > 0) %>% 
  filter(Sample.Type == "sample") %>% 
  ggplot(aes(x = Conc, fill = aboveThreshold))+
  geom_histogram(aes(y = ..count../sum(..count..)),bins = 38, alpha = 0.9, position = "identity") +
  #geom_text(aes(x = Threshold1- 0.5*Threshold1, y = 0.045), label = paste(Threshold1,"particles/L"),  color = "goldenrod2") +
  #geom_text(aes(x = Threshold1- 0.5*Threshold1, y = 0.055), label = ("Threshold1"),  color = "goldenrod2") +
  geom_vline(xintercept = Threshold1, linetype = 'dashed', color = 'goldenrod2', size = 1.3) +
  geom_vline(xintercept = Threshold2, linetype = 'dashed', color = 'tomato1', size = 1.3) +
  geom_vline(xintercept = Threshold3, linetype = 'dashed', color = 	'mediumvioletred', size = 1.3) +
  geom_vline(xintercept = Threshold4, linetype = 'dashed', color = 	'gray33', size = 1.3) +
  #geom_text(label = "Threshold 1", color = 'goldenrod2', x = log10(Threshold1) - 0.8*log10(Threshold1), y = 0.055, size = 6)+
#   geom_text(label = "Threshold 2", color = 'tomato1', x = log10(Threshold2) - 0.8*log10(Threshold2), y = 0.055, size = 6)+
 #  geom_text(label = "Threshold 3", color = 'mediumvioletred', x = log10(Threshold3) - 0.8*log10(Threshold3), y = 0.055, size = 6)+
  # geom_text(label = "Threshold 4", color = 'gray33', x = Threshold4 - 0.8*log10(Threshold4), y = 0.055, size = 6)+
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x),labels = comma_signif, trans = "log10")+
  annotation_logticks(sides = "b")+ #log scale rick marks on bottom
  #coord_cartesian(xlim = c(0,100000000)) +
  #scale_x_continuous(labels = scales::scientific) +
   xlab(paste0("Particles/L (" ,x1D_set, " to ", x2D_set, "μm)")) +
  scale_y_continuous(name = "Relative Density", labels = scales::percent)+
  scale_fill_manual(values = c("below Threshold 1"= "cyan3", 
                               "above Threshold 1" = "goldenrod2", 
                               "above Threshold 2" = "tomato1",
                               "above Threshold 3" = "violetred4", 
                               "above Threshold 4" = "gray33")) +
  labs(title = "San Francisco Bay Surface Water Marine Microplastics Concentrations",
       subtitle = paste("Particles/L corrected to:",x1D_set, "to", x2D_set, "um"),
       caption = paste("n = 107; corrected for size, blanks. Alpha = ",alpha.marine))+
  theme.type +
  theme(#legend.position = "none",
    plot.title = element_text(hjust = 0.5, size = 20),
        axis.title = element_text(size = 16),
        axis.text =  element_text(size = 16),
        legend.text = element_text(size =14),
        legend.title = element_blank(),
        plot.subtitle = element_text(hjust = 0.5, size = 14))
```
### ECDF (SF Bay)
##### All: Aligned vs. Unaligned

```{r}
vals <- c("Unaligned" = "black", "Aligned" = "deepskyblue")

#ECDF by System
sfBayECDF <- sfBay_new %>% 
  filter(source == "SFEI") %>% 
  drop_na(particle.L.master) %>% 
  filter(particle.L.master > 0.0) %>% 
    filter(System %in% c("Ocean", "Estuary")) %>% 
  ggplot() +
     #unaligned
  stat_ecdf(aes(x = unaligned.particle.L.master, color = "Unaligned"),
            geom = "point", size = 1, alpha = 0.5) +
  stat_ecdf(aes(x = unaligned.particle.L.master, color = "Unaligned"),geom = "step", linetype = 'solid', alpha = 0.3, size = 1) +
  #aligned
  stat_ecdf(aes(x = particle.L.master, color = "Aligned"),
            geom = "point", size = 1, alpha = 0.5) +
  stat_ecdf(aes(x = particle.L.master, color = "Aligned"),geom = "step", linetype = 'solid', alpha = 0.3, size = 1) +
  #color
  scale_color_manual(name = "alignment",
                     values = vals) +
  # ##Food Dilution thresholds
  geom_vline(xintercept = Threshold1_food, linetype = 'dashed', color = "#66a182", size = 1.3) +
  #geom_vline(xintercept = Threshold2, linetype = 'dashed', color = "#66a182" , size = 1.3) +
  #geom_vline(xintercept = Threshold3, linetype = 'dashed', color = 	'#edae49', size = 1.3) +
  geom_vline(xintercept = Threshold4_food, linetype = 'dashed', 
             color = "#d1495b",
             size = 1.3) +
  geom_text(label = "Food Dilution T1", color = "#66a182" , x = Threshold1_food, y = 0.15, size = 6)+
 # geom_text(label = "Threshold 2", color = "#66a182" , x = Threshold2, y = 0.22, size = 6)+
  #geom_text(label = "Threshold 3", color = '#edae49', x = Threshold3, y = 0.35, size = 6)+
  geom_text(label = "Food Dilution T4", color = "#d1495b", 
            x = Threshold4_food,
            y = 0.25, size = 6)+
  ###Oxidative Stress thresholds
  geom_vline(xintercept = Threshold1_oxidative.stress, linetype = 'dashed',
             color = "#66a182",#"#00798c",
             size = 1.3) +
  geom_vline(xintercept = Threshold4_oxidative.stress, linetype = 'dashed',
             color = "#d1495b",
             size = 1.3) +
  geom_text(label = "Oxidative Stress T1", color = "#66a182",#'#edae49',
            x = Threshold1_oxidative.stress - 0.8 * Threshold1_oxidative.stress, 
            y = 0.45, size = 6) +
  geom_text(label = "Oxidative Stress T4", color = "#d1495b", x =
              Threshold4_oxidative.stress - 0.8 * Threshold4_oxidative.stress, 
            y = 0.55, size = 6)+
    ylab("Cumulative Density") +
  xlab("Particles/L") +
  #xlab(paste0("Particles/L (" ,x1D_set, " to ", x2D_set, "um)"))+
  scale_y_continuous(labels = scales::percent)+
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x),labels = comma_signif)+
  #annotation_logticks(sides = "b")+ #log scale rick marks on bottom
  theme.type +
  theme(legend.title = element_blank(),
        legend.position = c(0.2,0.8),
        legend.text = element_text(size = 12, face = "bold"),
        legend.background = element_rect(fill = "white", color = "black"),
        legend.key.size = unit(1.3, 'cm'))
  #labs(title = "Global Surface Water Marine Microplastics Concentrations",
   #    subtitle = paste("Particles/L corrected to:",x1D_set, "to", x2D_set, "um"),
    #   caption = paste("Concentration data from Adams et al (2019): 23 studies, 57 sampling locations, n = 377; corrected for size ranges. Alpha = ",alpha))
 
sfBayECDF
```
```{r}
ggsave(plot =sfBayECDF,
       filename = "sfBayECDF.jpeg",
       path = "output/figures/", 
       width = 10, height = 6, units = "in",
       bg = "white",
       dpi = 300)
```

##### Sampling Technique x Alignment


```{r}
# need to pivot wide data into long format to easily plot
sfBayECDF_alignedXtechnique <- sfBay_new %>% 
  filter(source == "SFEI") %>% 
  filter(particle.L.master > 0) %>% 
  filter(sample.matrix.specific == "surface water") %>% 
  dplyr::select(c(sampleID, unaligned.particle.L.master, particle.L.master, Sampling.apparatus)) %>% 
  pivot_longer(-c(sampleID, Sampling.apparatus), names_to = "alignment", values_to = "concentration") %>% 
  #rename for easy plotting
  mutate(alignment_pretty = case_when(alignment == "particle.L.master" ~ "Aligned",
                                      alignment == "unaligned.particle.L.master" ~ "Unaligned")) %>% 
## PLOTTING ##
  ggplot(aes(x = concentration, color = interaction(Sampling.apparatus, alignment_pretty, sep = " x "))) +
  #aligned
  stat_ecdf(geom = "step", linetype = 'solid', size = 1) +
  #unaligned
  #color
  scale_color_manual(values = hcl(c(15,195,15,195),100,65, alpha=c(1,1, 0.3,0.3))) +
  #scale_alpha_manual(name = "alignment",
   #                 values = c(0.2,1)) +
  # ##Food Dilution thresholds
  geom_vline(xintercept = Threshold1_food, linetype = 'dashed', color = "#85a17d", size = 1) +
  geom_text(label = "Food Dilution T1", color = "#85a17d" , x = Threshold1_food, y = 0.10, size = 5)+
  geom_vline(xintercept = Threshold2_food, linetype = 'dashed', color = "#ebbb38", size = 1) +
  geom_text(label = "Food Dilution T2", color = "#ebbb38" , x = Threshold2_food, y = 0.15, size = 5)+
  geom_vline(xintercept = Threshold3_food, linetype = 'dashed', color = "#fd8060", size = 1) +
  geom_text(label = "Food Dilution T3", color = "#fd8060" , x = Threshold3_food, y = 0.20, size = 5)+
  geom_vline(xintercept = Threshold4_food, linetype = 'dashed', color = "#E84258", size = 1) +
  geom_text(label = "Food Dilution T4", color = "#E84258",  x = Threshold4_food, y = 0.25, size = 5)+
  #aesthetics
    ylab("Cumulative Density") +
  labs(color = "Sampling technique x Alignment") +
  xlab("Particles/L") +
  #xlab(paste0("Particles/L (" ,x1D_set, " to ", x2D_set, "um)"))+
  scale_y_continuous(labels = scales::percent)+
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x),labels = comma_signif)+
  #annotation_logticks(sides = "b")+ #log scale rick marks on bottom
  theme.type +
  theme(legend.position = "bottom")
  #labs(title = "Global Surface Water Marine Microplastics Concentrations",
   #    subtitle = paste("Particles/L corrected to:",x1D_set, "to", x2D_set, "um"),
    #   caption = paste("Concentration data from Adams et al (2019): 23 studies, 57 sampling locations, n = 377; corrected for size ranges. Alpha = ",alpha))
 
sfBayECDF_alignedXtechnique
```
```{r}
ggsave(plot = sfBayECDF_alignedXtechnique,
       filename = "sfBayECDF_alignedXtechnique.jpeg",
       path = "output/figures/", 
       width = 10, height = 6, units = "in",
       scale = 1.2,
       bg = "white",
       dpi = 300)
```

#Compare fish concentrations and ambient
Two-Way ANOVA needed!!
```{r}
#group by location name and compare averages/sds by ambient and fish
all_data <- sfBay_aligned %>%
  filter(!Sampling.apparatus == "1-L grab") %>% 
  mutate(particles.any = case_when(
    sample.matrix == "water" ~ particle.L.master,
    sample.matrix == "fish" ~ particle.fish.master,
    sample.matrix == "sediment" ~ particles.kg.master
    ))
  
all_data_summary <- all_data %>% 
  group_by(Sampling.location, sample.matrix) %>% 
  summarize(mean = mean(particles.any),
            sd = sd(particles.any),
            n = n())


all_data_summary %>% 
  drop_na() %>% 
  ggplot(aes(x = Sampling.location,y = mean, color = sample.matrix))+
  geom_point() +
  scale_y_log10()
```
## ANOVA
```{r}
ANOVA <- aov(data = all_data, particles.any ~ sample.matrix * Sampling.location)

anova_table <- summary(ANOVA)

anova_table

new <- all_data %>%  filter(Sampling.location %in% c("South Bay", "Lower South Bay", "Central Bay"))

# library(apaTables)
# apa.aov.table(dv = particles.any,
#                iv1 = sample.matrix,
#                iv2 = Sampling.location,
#                data = new,
#                filename = "output/ANOVA.doc",
#              #  show.marginal.means = TRUE
#                )
```
## Boxplots by matrix
```{r}

violin_matrix <- all_data %>% 
  drop_na(Sampling.location) %>% 
   filter(!Sampling.apparatus == "1-L grab") %>% 
  filter(Sampling.location %in% c("South Bay", "Lower South Bay", "Central Bay")) %>% 
  mutate(location = fct_reorder(Sampling.location, desc(particles.any))) %>%
  ggplot(aes(y = location, x = particles.any, fill = sample.matrix)) +
  geom_violin(position = "identity", trim = FALSE) +
  geom_boxplot(width=0.1, color = "white", position = "identity") +
  scale_fill_futurama(name = "Sample Matrix",
                       labels = c("Fish (particles/fish)",
                                  "Sediment (particles/kg)",
                                  "Surface Water (particles/L)")) +
  scale_x_log10(name = "Aligned Particle Concentrations (matrix-dependent)",
                  breaks = scales::trans_breaks("log10", function(x) 10^x),
        labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  theme.type +
  theme(legend.position = "bottom",
        axis.title.y = element_blank())


ggsave(plot = violin_matrix,
       filename = "violin_matrix.jpeg",
       path = "output/figures/", 
       width = 11, height = 9, units = "in",
       bg = "white",
       dpi = 300)

violin_matrix
```

```{r}

sfBay_aligned %>% 
  filter(!sampleID == "CB9 Jan 11 Total") %>% 
  filter(!Sampling.apparatus == "1-L grab") %>% 
  mutate(scaled.particle.L.master = scale(particle.L.master),
         scaled.fish.master = scale(particle.fish.master),
         scaled.particles.kg.master = scale(particles.kg.master)) %>% 
  mutate(particles.any.scaled = case_when(
    sample.matrix == "water" ~ scaled.particle.L.master,
    sample.matrix == "fish" ~ scaled.fish.master,
    sample.matrix == "sediment" ~ scaled.particles.kg.master
    )) %>% 
  drop_na(Sampling.location) %>% 
 ggplot(aes(y = particles.any.scaled, x = Sampling.location, color = sample.matrix)) +
  geom_boxplot() +
  #scale_y_log10()+
  theme.type 

```

